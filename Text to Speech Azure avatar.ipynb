{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873786b9",
   "metadata": {},
   "source": [
    "# Text to Speech avatar\n",
    "\n",
    "## From text to speech with a video avatar provided by Azure Speech Services\n",
    "Custom text to speech avatar allows you to create a customized, one-of-a-kind synthetic talking avatar for your application. With custom text to speech avatar, you can build a unique and natural-looking avatar for your product or brand by providing video recording data of your selected actors. If you also create a custom neural voice for the same actor and use it as the avatar's voice, the avatar will be even more realistic.\n",
    "\n",
    "<img src=\"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech-avatar/media/custom-avatar-workflow.png#lightbox\">\n",
    "\n",
    "> https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech-avatar/what-is-custom-text-to-speech-avatar \n",
    "> https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-speech-announces-public-preview-of-text-to-speech/ba-p/3981448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install moviepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0441c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from ipywidgets import Video\n",
    "from IPython.display import display\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52c29b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df759539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 15-May-2024 10:36:08\n"
     ]
    }
   ],
   "source": [
    "dt = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "print(f\"Today is {dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65f1edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s] %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %I:%M:%S %p %Z\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a4adb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Speech services informations\n",
    "azure_speech_key = \"bfb7797bd9e74a26b52ddcd253edef56\"\n",
    "azure_speech_region = \"eastus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eef643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_host = \"customvoice.api.speech.microsoft.com\"  # Do not change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40bc904",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8be425bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_synthesis(prompt):\n",
    "    url = f\"https://{azure_speech_region}.{service_host}/api/texttospeech/3.1-preview1/batchsynthesis/talkingavatar\"\n",
    "\n",
    "    header = {\n",
    "        \"Ocp-Apim-Subscription-Key\": azure_speech_key,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"displayName\": \"Simple avatar synthesis\",\n",
    "        \"description\": \"Simple avatar synthesis description\",\n",
    "        \"textType\": \"PlainText\",\n",
    "        \"synthesisConfig\": {\n",
    "            \"voice\": \"en-US-JennyNeural\",\n",
    "        },\n",
    "        \"customVoices\": {\n",
    "            # \"YOUR_CUSTOM_VOICE_NAME\": \"YOUR_CUSTOM_VOICE_ID\"\n",
    "        },\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        \"properties\": {\n",
    "            \"customized\": False,  # set to True if you want to use customized avatar\n",
    "            \"talkingAvatarCharacter\": \"lisa\",  # talking avatar character\n",
    "            \"talkingAvatarStyle\": \"graceful-sitting\",  # talking avatar style, required for prebuilt avatar, optional for custom avatar\n",
    "            \"videoFormat\": \"webm\",  # mp4 or webm, webm is required for transparent background\n",
    "            \"videoCodec\": \"vp9\",  # hevc, h264 or vp9, vp9 is required for transparent background; default is hevc\n",
    "            \"subtitleType\": \"soft_embedded\",\n",
    "            \"backgroundColor\": \"transparent\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json.dumps(payload), headers=header)\n",
    "\n",
    "    if response.status_code < 400:\n",
    "        logger.info(\"Batch avatar synthesis job submitted successfully\")\n",
    "        logger.info(f'Job ID: {response.json()[\"id\"]}')\n",
    "        return response.json()[\"id\"]\n",
    "\n",
    "    else:\n",
    "        logger.error(f\"Failed to submit batch avatar synthesis job: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9882191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthesis(job_id):\n",
    "    global avatar_url\n",
    "    url = f\"https://{azure_speech_region}.{service_host}/api/texttospeech/3.1-preview1/batchsynthesis/talkingavatar/{job_id}\"\n",
    "\n",
    "    header = {\"Ocp-Apim-Subscription-Key\": azure_speech_key}\n",
    "\n",
    "    response = requests.get(url, headers=header)\n",
    "\n",
    "    if response.status_code < 400:\n",
    "        logger.debug(\"Get batch synthesis job successfully\")\n",
    "        logger.debug(response.json())\n",
    "\n",
    "        status = response.json()[\"status\"]\n",
    "\n",
    "        if status == \"Succeeded\":\n",
    "            avatar_url = response.json()[\"outputs\"][\"result\"]\n",
    "            logger.info(f\"Batch synthesis job succeeded, download URL: {avatar_url}\")\n",
    "\n",
    "        return status\n",
    "    else:\n",
    "        logger.error(f\"Failed to get batch synthesis job: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49770f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_synthesis_jobs(skip: int = 0, top: int = 100):\n",
    "    \"\"\"List all batch synthesis jobs in the subscription\"\"\"\n",
    "\n",
    "    url = f\"https://{azure_speech_region}.{service_host}/api/texttospeech/3.1-preview1/batchsynthesis/talkingavatar?skip={skip}&top={top}\"\n",
    "\n",
    "    header = {\"Ocp-Apim-Subscription-Key\": azure_speech_key}\n",
    "\n",
    "    response = requests.get(url, headers=header)\n",
    "\n",
    "    if response.status_code < 400:\n",
    "        logger.info(\n",
    "            f'List batch synthesis jobs successfully, got {len(response.json()[\"values\"])} jobs'\n",
    "        )\n",
    "        logger.info(response.json())\n",
    "    else:\n",
    "        logger.error(f\"Failed to list batch synthesis jobs: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb178ad7",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b65c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "I am Lisa, your avatar powered by Azure Speech Services.\n",
    "Today is {dt}.\n",
    "\n",
    "Let me explain you what is Azure Open AI service.\n",
    "\n",
    "Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-4, GPT-3.5-Turbo, and Embeddings model series. In addition, the new GPT-4 and GPT-3.5-Turbo model series have now reached general availability. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\n",
    "\n",
    "At Microsoft, we're committed to the advancement of AI driven by principles that put people first. Generative models such as the ones available in Azure OpenAI have significant potential benefits, but without careful design and thoughtful mitigations, such models have the potential to generate incorrect or even harmful content. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases, incorporating Microsoft’s principles for responsible AI use, building content filters to support customers, and providing responsible AI implementation guidance to onboarded customers.\n",
    "\n",
    "To learn more go to https://azure.microsoft.com/en-us/products/ai-services/ai-speech\n",
    "\n",
    "Thank you and have a good day.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c824a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am Lisa, your avatar powered by Azure Speech Services.\n",
      "Today is 15-May-2024 10:32:50.\n",
      "\n",
      "Let me explain you what is Azure Open AI service.\n",
      "\n",
      "Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-4, GPT-3.5-Turbo, and Embeddings model series. In addition, the new GPT-4 and GPT-3.5-Turbo model series have now reached general availability. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\n",
      "\n",
      "At Microsoft, we're committed to the advancement of AI driven by principles that put people first. Generative models such as the ones available in Azure OpenAI have significant potential benefits, but without careful design and thoughtful mitigations, such models have the potential to generate incorrect or even harmful content. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases, incorporating Microsoft’s principles for responsible AI use, building content filters to support customers, and providing responsible AI implementation guidance to onboarded customers.\n",
      "\n",
      "To learn more go to https://azure.microsoft.com/en-us/products/ai-services/ai-speech\n",
      "\n",
      "Thank you and have a good day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b315fc2",
   "metadata": {},
   "source": [
    "## Avatar batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d69fbed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/15/2024 10:36:31 AM India Standard Time] Batch avatar synthesis job submitted successfully\n",
      "[05/15/2024 10:36:31 AM India Standard Time] Job ID: df6346b1-7533-49f6-a06e-0c631721c11e\n",
      "[05/15/2024 10:36:33 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:37:05 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:37:36 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:38:08 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:38:39 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:39:11 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:39:42 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:40:14 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:40:46 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:41:17 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:41:49 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:42:21 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:42:52 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:43:24 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:43:55 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:44:27 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:45:05 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:45:37 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:46:08 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:46:40 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:47:12 AM India Standard Time] Please wait. Status: [Running]\n",
      "[05/15/2024 10:47:44 AM India Standard Time] Batch synthesis job succeeded, download URL: https://cvoiceprodeus.blob.core.windows.net/batch-synthesis-output/df6346b1-7533-49f6-a06e-0c631721c11e/0001.webm?skoid=85130dbe-2390-4897-a9e9-5c88bb59daff&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skt=2024-05-15T05%3A12%3A43Z&ske=2024-05-21T05%3A17%3A43Z&sks=b&skv=2023-11-03&sv=2023-11-03&st=2024-05-15T05%3A12%3A43Z&se=2024-05-16T05%3A17%3A43Z&sr=b&sp=rl&sig=Jb1HtDR%2FB0Pa0cqUa7Qu%2B1Gq2cFYJ8SIUtY6WEOn0o0%3D\n",
      "[05/15/2024 10:47:44 AM India Standard Time] Done! Azure batch avatar synthesis job succeeded.\n",
      "Elapsed time: 00:11:13.890464\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "job_id = submit_synthesis(prompt)\n",
    "\n",
    "if job_id is not None:\n",
    "    while True:\n",
    "        status = get_synthesis(job_id)\n",
    "        if status == \"Succeeded\":\n",
    "            logger.info(\"Done! Azure batch avatar synthesis job succeeded.\")\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Elapsed time: \" + time.strftime(\"%H:%M:%S.{}\".format(str(elapsed % 1)[2:])[:15],\n",
    "                                                   time.gmtime(elapsed)))\n",
    "\n",
    "            break\n",
    "        elif status == \"Failed\":\n",
    "            logger.error(\"Failed\")\n",
    "            break\n",
    "        else:\n",
    "            logger.info(f\"Please wait. Status: [{status}]\")\n",
    "            time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b22e3",
   "metadata": {},
   "source": [
    "## Avatar video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "973f2119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mThis is the prompt to speak:\n",
      " \n",
      "I am Lisa, your avatar powered by Azure Speech Services.\n",
      "Today is 15-May-2024 10:36:08.\n",
      "\n",
      "Let me explain you what is Azure Open AI service.\n",
      "\n",
      "Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-4, GPT-3.5-Turbo, and Embeddings model series. In addition, the new GPT-4 and GPT-3.5-Turbo model series have now reached general availability. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\n",
      "\n",
      "At Microsoft, we're committed to the advancement of AI driven by principles that put people first. Generative models such as the ones available in Azure OpenAI have significant potential benefits, but without careful design and thoughtful mitigations, such models have the potential to generate incorrect or even harmful content. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases, incorporating Microsoft’s principles for responsible AI use, building content filters to support customers, and providing responsible AI implementation guidance to onboarded customers.\n",
      "\n",
      "To learn more go to https://azure.microsoft.com/en-us/products/ai-services/ai-speech\n",
      "\n",
      "Thank you and have a good day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1;31;34mThis is the prompt to speak:\\n {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28b67132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/15/2024 11:02:09 AM India Standard Time] c:\\Users\\ParveenKR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file https://cvoiceprodeus.blob.core.windows.net/batch-synthesis-output/df6346b1-7533-49f6-a06e-0c631721c11e/0001.webm?skoid=85130dbe-2390-4897-a9e9-5c88bb59daff&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skt=2024-05-15T05%3A12%3A43Z&ske=2024-05-21T05%3A17%3A43Z&sks=b&skv=2023-11-03&sv=2023-11-03&st=2024-05-15T05%3A12%3A43Z&se=2024-05-16T05%3A17%3A43Z&sr=b&sp=rl&sig=Jb1HtDR%2FB0Pa0cqUa7Qu%2B1Gq2cFYJ8SIUtY6WEOn0o0%3D, 6220800 bytes wanted but 0 bytes read,at frame 2686/2687, at time 107.44/107.45 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save avatar video\n",
    "\n",
    "avatar_file = (\n",
    "    \"azure_avatar_\" + str(datetime.datetime.today().strftime(\"%d%b%Y_%H%M%S\")) + \".mp4\"\n",
    ")\n",
    "VideoFileClip(avatar_url).write_videofile(avatar_file, verbose=False, logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4275e901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8097f27628f84358b8b5450b2b523b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free...')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing the avatar video\n",
    "\n",
    "Video.from_file(avatar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad125c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
